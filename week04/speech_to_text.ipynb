{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa384ff-f193-4f5e-82fd-74ad47642be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install moviepy\n",
    "#!pip install mutagen\n",
    "#!pip install transformers\n",
    "#!pip install datasets\n",
    "#!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044504d9-0273-41e9-a1e5-3306db006745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "from mutagen.mp3 import MP3\n",
    "import torch\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "import librosa\n",
    "from transformers import AutoTokenizer, AutoFeatureExtractor, AutoModelForCTC\n",
    "import timeit\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ddc16b-f847-4910-b353-da451fd5e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio(video):\n",
    "    v = re.findall(r\"(.*?)\\.mp4\", video)[0]\n",
    "    my_clip = mp.VideoFileClip(f\"{path}{video}\")\n",
    "    my_clip.audio.write_audiofile(f\"recording_{v}.mp3\")\n",
    "    \n",
    "def calculate_length(video, extension):\n",
    "    v = re.findall(f\"(.*?)\\.{extension}\", video)[0]\n",
    "    audio = MP3(f\"recording_{v}.mp3\")\n",
    "    return round(audio.info.length)\n",
    "\n",
    "def extract_text(video, length, processor, model, overlap, extension, audio_path):\n",
    "    v = re.findall(f\"(.*?)\\.{extension}\", video)[0]\n",
    "    intervals = list(range(0, length, (30-overlap))) \n",
    "    duration = [30]* int(len(intervals)-1)\n",
    "    duration.append(length-intervals[-1])\n",
    "    cc = []\n",
    "    for intv, dur in zip(intervals, duration):\n",
    "        try:\n",
    "            # Load 30 seconds of a file, starting intv seconds in\n",
    "            y, sr = librosa.load(f\"{audio_path}{v}.mp3\", sr=16000, offset=intv, duration=dur)\n",
    "            inputs = processor(y, return_tensors=\"pt\", padding=\"longest\", sampling_rate=16000)\n",
    "            input_features = inputs.input_features\n",
    "            generated_ids = model.generate(inputs=input_features)\n",
    "            transcription = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "            cc.append(transcription)\n",
    "            with open(f\"text_{v}.txt\", \"a+\") as f:\n",
    "                f.write(f\"{transcription}\\n\")   \n",
    "        except (RuntimeError, NameError) as e:\n",
    "            #print(e)\n",
    "            print(length-intv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75180483-ea7f-4782-b647-7137b5cec071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(video_files, audio_path):\n",
    "    done = [] #if you don't want to run all the text extraction in once, \n",
    "              #you can provide a list of previously processed files\n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-large\")\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large\")\n",
    "    start = timeit.default_timer()\n",
    "    for video in video_files:\n",
    "        if video not in done and video.endswith(\"mp4\"):\n",
    "            extract_audio(video)\n",
    "            length = calculate_length(video, \"mp4\")\n",
    "            extract_text(video, length, processor, model, 3, \"mp4\")\n",
    "            done.append(video)\n",
    "        elif video not in done and video.endswith(\"mp3\"):\n",
    "            audio = MP3(f\"{path}{video}\")\n",
    "            length = round(audio.info.length)\n",
    "            extract_text(video, length, processor, model, 3, \"mp3\", audio_path)\n",
    "            done.append(video)\n",
    "        else:\n",
    "            print(video, \"Extension not supported! Please provide a valid file, such as mp4 or mp3\")\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    print('Time: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4bb9ec-ffa1-40dd-a44b-b3a1f061e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\" #add path to your MP4 or MP3 files\n",
    "video_files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "run(video_files, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5218a1db-c036-434c-86a8-0b3a5ad70d9a",
   "metadata": {},
   "source": [
    "Let's visualize a wave!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8abb518-013e-47c6-a27d-5e6de0e5a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_wave(recording):\n",
    "    '''\n",
    "    This function is used to visualize an audio file, given in MP3 format.\n",
    "    '''\n",
    "    y, sr = librosa.load(recording, sr=16000, duration=30)\n",
    "    plt.figure(figsize=(7,3))\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title('Wave')\n",
    "    plt.savefig('wave.png', format='png', transparent=True)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
