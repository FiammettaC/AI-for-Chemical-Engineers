{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb7838a5-058b-4ee4-87f0-9787a57cad3b",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b1c8dd-4a00-4168-b2e7-ebdcd7afe98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def dataset_split(X, y):\n",
    "    X_train, X_t, y_train, y_t = train_test_split(X, y, test_size=.2)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_t, y_t, test_size=.5)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "#print('Train set size: ', len(X_train), len(y_train))\n",
    "#print('Validation set size: ', len(X_val), len(y_val))\n",
    "#print('Test set size: ', len(X_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc289bd6-8c7b-4f9c-8482-44a023154a22",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4209d18e-85cd-46bf-b33c-48a7e81311b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define evaluation function\n",
    "def evaluation(model, X_test, y_test):\n",
    "    prediction = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, prediction)\n",
    "    mse = mean_squared_error(y_test, prediction)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, prediction))\n",
    "    r2 = sklearn.metrics.r2_score(y_test, prediction)\n",
    "    \n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(prediction[:300], \"red\", label=\"Predictions\", linewidth=1.0)\n",
    "    plt.plot(y_test[:300], 'green', label=\"Observations\", linewidth=1.0)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    x = np.linspace(y_test.min(),y_test.max(), 100)\n",
    "    y = x\n",
    "    #m, b = np.polyfit(y_test, prediction, 1)\n",
    "    #plt.plot(y_test, m*y_test + b, '--', color='red', label='regression line')\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(y_test, prediction, alpha=0.5, label='logP predictions')\n",
    "    plt.plot(x, y, '--', color='black', label='regression line')\n",
    "    #plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel('Observations')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.ylabel('logP')\n",
    "    #plt.title(\"MAE {}, MSE {}\".format(round(mae, 4), round(mse, 4)))\n",
    "    plt.title(\"Parity plot of the observed and predicted target values\")\n",
    "    plt.show()\n",
    "    \n",
    "    print('MAE score:', round(mae, 4))\n",
    "    print('MSE score:', round(mse, 4))\n",
    "    print('RMSE score:', round(rmse, 4))\n",
    "    print('R2 score:', round(r2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6464c96-743f-43e3-82c7-38009bc6cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "import xgboost\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "# Linear Regression\n",
    "lin_reg = LinearRegression().fit(X_train, y_train)\n",
    "#evaluation(lin_reg, X_val, y_val)\n",
    "\n",
    "#SVR\n",
    "svr_rbf = SVR(kernel='rbf').fit(X_train, y_train)\n",
    "#evaluation(svr_rbf, X_val, y_val)\n",
    "\n",
    "#XGBoost\n",
    "xgb = XGBRegressor(n_estimators=1000, max_depth=6, eta=0.3, subsample=0.7, colsample_bytree=0.8, reg='squarederror').fit(X_train, y_train)\n",
    "#evaluation(xgb, X_val, y_val)\n",
    "\n",
    "# Ensemble\n",
    "ereg = VotingRegressor(estimators=[('lr', lin_reg), ('svr', svr_rbf), ('xgb', xgb)])\n",
    "#ereg = ereg.fit(X_train, y_train)\n",
    "#evaluation(ereg, X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1340c8-9940-404f-a191-30b8108ba50c",
   "metadata": {},
   "source": [
    "Calculating the performance on an unseen test set is very important to prevent having a biased model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9878f2f-e618-4e1c-9efe-18e445251a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final models\n",
    "#evaluation(lin_reg, X_test, y_test)\n",
    "#evaluation(svr_rbf, X_test, y_test)\n",
    "#evaluation(xgb, X_test, y_test)\n",
    "#evaluation(ereg, X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
