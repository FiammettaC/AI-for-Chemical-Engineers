{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced50d5a-6b7f-405b-81c8-e37f440edb52",
   "metadata": {},
   "source": [
    "This project was done in collaboration with Lars Stegem√ºller.\n",
    "Paper can be found [here](https://www.sciencedirect.com/science/article/pii/S0960852424016808).\n",
    "Code and data can be found [here](https://github.com/stegemlar/microalgae-image/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8506c27-265e-4611-9383-44ed89a35951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "import glob\n",
    "import plotly\n",
    "import plotly.express as ex\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras.models import Model,load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout,Conv2D,Flatten,MaxPooling2D\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "import visualkeras\n",
    "from keras.utils import plot_model\n",
    "from keras_tuner.tuners import GridSearch\n",
    "from keras_tuner import HyperModel\n",
    "from keras_tuner.tuners import Hyperband\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc8598c-bd71-44a1-a65c-221d5881a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Images are of different sizes fixing the size to 64 x 64\n",
    "im_size = 64\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d025d22-2f4f-4116-ad09-240dd0f1babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training and Validation Data Generator with Augmentations\n",
    "gen = ImageDataGenerator(\n",
    "    rescale=1/255.,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=0.4,\n",
    "    zoom_range=0.4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f256a349-8db7-4fb8-9e4d-59d3090e2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data here\n",
    "\n",
    "filepath_train = #Define file path for train set here\n",
    "filepath_test = #Define file path for train set here\n",
    "filepath_val = #Define file path for train set here\n",
    "\n",
    "Train_gen = gen.flow_from_directory(\n",
    "    filepath_train,\n",
    "    target_size=(im_size, im_size),\n",
    "    color_mode='grayscale',  \n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'  \n",
    ")\n",
    "Test_gen = gen.flow_from_directory(\n",
    "    filepath_test,\n",
    "    target_size=(im_size, im_size),\n",
    "    color_mode='grayscale',  \n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'  \n",
    ")\n",
    "\n",
    "Val_gen = gen.flow_from_directory(\n",
    "    filepath_val,\n",
    "    target_size=(im_size, im_size),\n",
    "    color_mode='grayscale',  \n",
    "    batch_size=1,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ba192-b611-432a-be7b-c40b81ae7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_gen.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2717dd7c-2e99-4456-99a8-e76347fb9b6f",
   "metadata": {},
   "source": [
    "## Basic Model (Updated with optimised parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b1ce39c5-d773-4dca-bbd2-551e126362d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (64, 64, 1)\n",
    "NUM_CLASSES = 5\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=32,\n",
    "        kernel_size=3,\n",
    "        activation='relu',\n",
    "        input_shape=INPUT_SHAPE\n",
    "    )\n",
    ")\n",
    "model.add(Conv2D(32, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(rate=0.1))\n",
    "model.add(Conv2D(32, 3, activation='relu'))\n",
    "model.add(Conv2D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(rate=0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=1024, activation='relu'))\n",
    "model.add(Dropout(rate=0.45))\n",
    "model.add(Dense(NUM_CLASSES, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a7b3b84-6030-4bca-bd5b-a6429625b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model \n",
    "#Learning rate adjusted from optimisation\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001113421743399749),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d0033-869a-4e91-8498-dce328d3deaa",
   "metadata": {},
   "source": [
    "# Only use for optimisation\n",
    "### disable with esc +r / enable with esc+y"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c78d742f-633c-4de4-b364-99079fad4cf3",
   "metadata": {},
   "source": [
    "# Create the Hyper model for optimisation\n",
    "class CNNHyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=16,\n",
    "                kernel_size=3,\n",
    "                activation='relu',\n",
    "                input_shape=self.input_shape\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=16,\n",
    "                activation='relu',\n",
    "                kernel_size=3\n",
    "            )\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(\n",
    "            Dropout(rate=hp.Float(\n",
    "                'dropout_1',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            ))\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=32,\n",
    "                kernel_size=3,\n",
    "                activation='relu'\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Conv2D(\n",
    "                filters=hp.Choice(\n",
    "                    'num_filters',\n",
    "                    values=[32, 64],\n",
    "                    default=64,\n",
    "                ),\n",
    "                activation='relu',\n",
    "                kernel_size=3\n",
    "            )\n",
    "        )\n",
    "        model.add(MaxPooling2D(pool_size=2))\n",
    "        model.add(\n",
    "            Dropout(rate=hp.Float(\n",
    "                'dropout_2',\n",
    "                min_value=0.0,\n",
    "                max_value=0.5,\n",
    "                default=0.25,\n",
    "                step=0.05,\n",
    "            ))\n",
    "        )\n",
    "        model.add(Flatten())\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=hp.Int(\n",
    "                    'units',\n",
    "                    min_value=32,\n",
    "                    max_value=512,\n",
    "                    step=32,\n",
    "                    default=128\n",
    "                ),\n",
    "                activation=hp.Choice(\n",
    "                    'dense_activation',\n",
    "                    values=['relu', 'tanh', 'sigmoid'],\n",
    "                    default='relu'\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        model.add(\n",
    "            Dropout(\n",
    "                rate=hp.Float(\n",
    "                    'dropout_3',\n",
    "                    min_value=0.0,\n",
    "                    max_value=0.5,\n",
    "                    default=0.25,\n",
    "                    step=0.05\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "        model.add(Dense(self.num_classes, activation='softmax'))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                hp.Float(\n",
    "                    'learning_rate',\n",
    "                    min_value=1e-4,\n",
    "                    max_value=1e-2,\n",
    "                    sampling='LOG',\n",
    "                    default=1e-3\n",
    "                )\n",
    "            ),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "\n",
    "hypermodel = CNNHyperModel(input_shape=INPUT_SHAPE, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f549e716-e4a1-4ca5-b010-a5f6b8dbdd6a",
   "metadata": {},
   "source": [
    "# Use Hyperband to optimise\n",
    "tuner = Hyperband(\n",
    "    hypermodel,\n",
    "    max_epochs=100,\n",
    "    objective='val_accuracy',\n",
    "    executions_per_trial=2,\n",
    "    directory='hyperband',\n",
    "    project_name='test'\n",
    ")\n",
    "\n",
    "N_EPOCH_SEARCH = 10\n",
    "\n",
    "tuner.search(Train_gen,\n",
    "             epochs=N_EPOCH_SEARCH,\n",
    "             validation_data=Test_gen,\n",
    "             steps_per_epoch=Train_gen.samples // Train_gen.batch_size,\n",
    "             validation_steps=Test_gen.samples // Test_gen.batch_size)\n",
    "\n",
    "# Show a summary of the search\n",
    "tuner.results_summary()\n",
    "\n",
    "# Retrieve the best model.\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "590267ca-0ce8-4e09-9848-b3748860c265",
   "metadata": {},
   "source": [
    "# Show a summary of the search\n",
    "tuner.results_summary()\n",
    "\n",
    "# Retrieve the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model using the test generator\n",
    "loss, accuracy = best_model.evaluate(Val_gen, steps=Val_gen.samples // Val_gen.batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d73f3d-9162-4438-95c5-7e63a484c9f1",
   "metadata": {},
   "source": [
    "# Continue here after model was optimised\n",
    "### Check that optimal parameters were added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882866ca-1d33-4ba7-b153-1fa25fa7062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "hist = model.fit(\n",
    "    Train_gen,\n",
    "    epochs=200,\n",
    "    validation_data=Test_gen\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1134d2d9-ce86-47df-9c25-58c37a061e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model,\n",
    "model.save(\"best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad30402-30a3-45ec-87a4-1a5bedbfe634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Train accuracy\n",
    "history_dict = hist.history\n",
    "\n",
    "print(history_dict.keys())\n",
    "\n",
    "train_acc = history_dict['accuracy']\n",
    "\n",
    "final_train_accuracy = train_acc[-1]\n",
    "print(f\"Final Training Accuracy: {final_train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e3e5d-bcb5-40f8-9bbe-8cc60bca5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true labels\n",
    "true_labels = Val_gen.classes\n",
    "\n",
    "#Load model\n",
    "model = load_model()  #Adjust file location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6338cb0-e9dd-413f-a87e-055df7debd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 10s 27ms/step\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "Val_gen.reset() \n",
    "predictions = model.predict(Val_gen, steps=len(Val_gen))\n",
    "\n",
    "predicted_classes = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54c76c-0ed1-4e6e-b4dc-d36afab5b6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of validation (Confusion matrix)\n",
    "cm = confusion_matrix(true_labels, predicted_classes)\n",
    "\n",
    "cm_percentage = cm / np.sum(cm, axis=1)[:, np.newaxis]  \n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))  \n",
    "sns.heatmap(cm, annot=False, fmt=\"d\", cmap=\"viridis\", \n",
    "            xticklabels=sorted(Val_gen.class_indices, key=Val_gen.class_indices.get), \n",
    "            yticklabels=sorted(Val_gen.class_indices, key=Val_gen.class_indices.get), ax=ax)\n",
    "\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        color = \"black\" if i == j else \"#FCE625\"  \n",
    "        ax.text(j + 0.5, i + 0.5, format(cm_percentage[i, j] * 100, '.1f'),\n",
    "                ha=\"center\", va=\"center\", color=color, fontsize=14)\n",
    "\n",
    "\n",
    "ax.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "plt.ylabel('True Label',fontsize=14)\n",
    "plt.xlabel('Predicted Label',fontsize=14)\n",
    "plt.show()\n",
    "\n",
    "# Save the plot to a file\n",
    "ax.figure.savefig('CNN_confusion.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e6918c-15cf-4b46-8215-9db0bdc275bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Validation accuracy\n",
    "val_accuracy = accuracy_score(true_labels, predicted_classes)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3152487-506b-46dc-8fef-68d4e7ff2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model structure\n",
    "\n",
    "plot_model(model, to_file='model_structure.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(filename='model_structure.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8683a4e",
   "metadata": {},
   "source": [
    "## Explainability (SHAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51030ae",
   "metadata": {},
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4e7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "import shap\n",
    "\n",
    "\n",
    "# load pre-trained model and data\n",
    "#model = ResNet50(weights=\"imagenet\")\n",
    "model = load_model(#add model direction here) \n",
    "X, y = next(Test_gen)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "y_cat = np.argmax(y, axis=1)\n",
    "print(y_cat)\n",
    "print(y_cat.shape)\n",
    "class_names = [keys for (keys, values) in Test_gen.class_indices.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b6dd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python function to get model output; replace this function with your own model function.\n",
    "def f(x):\n",
    "    predictions = model.predict(x, steps=len(x))\n",
    "    # print(predictions)\n",
    "    #predicted_classes = np.argmax(predictions, axis=1)\n",
    "    #K.constant(predicted_classes)\n",
    "    predicted_classes = tf.convert_to_tensor(predictions, dtype=tf.float32)\n",
    "    return predicted_classes\n",
    "\n",
    "# define a masker that is used to mask out partitions of the input image.\n",
    "masker = shap.maskers.Image(\"inpaint_telea\", X[0].shape)\n",
    "masker_blur = shap.maskers.Image(\"blur(128,128)\", X[0].shape)\n",
    "\n",
    "\n",
    "# create an explainer with model and image masker\n",
    "explainer = shap.Explainer(f, masker_blur, output_names=class_names)\n",
    "\n",
    "# here we explain two images using 500 evaluations of the underlying model to estimate the SHAP values\n",
    "shap_values = explainer(\n",
    "    X[:], max_evals=5000, batch_size=50, outputs=shap.Explanation.argsort.flip[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output with shap values\n",
    "shap.image_plot(shap_values)\n",
    "\n",
    "print(y_cat[:])\n",
    "print(Train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = Test_gen[0]\n",
    "y_cat_batch = np.argmax(y_batch, axis=1)\n",
    "\n",
    "shap_values_batch = explainer(\n",
    "    X_batch[:], max_evals=5000, batch_size=50, outputs=shap.Explanation.argsort.flip[:])\n",
    "\n",
    "shap.image_plot(shap_values_batch)\n",
    "print(y_cat_batch[:])\n",
    "print(Train_gen.class_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
